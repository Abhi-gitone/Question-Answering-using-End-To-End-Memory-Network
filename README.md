# Question-Answering-using-End-To-End-Memory-Network-for-Natural-Language-Processing-in-Python

Trained an End-To-End Memory Network on 10,000 datapoints of the bAbI dataset from Meta Research for question answering.
The model was trained for 120 epochs with a batch size of 32 with multiple dropout layers between 0.3 and 0.5, yielding 81.3% accuracy.

Suggested improvements: avoid overfitting by increasing batch size to 64, and reduce epochs to anywhere between 40 and 60.
